import os
import re
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font
from openpyxl import load_workbook
from config import CONFIG, REVERSE_MAPPING
from excel_utils import (
    adjust_column_width, 
    merge_header_for_summary, 
    mark_unmatched_keys_on_sheet,
    mark_keys_on_sheet
)
from mapping_utils import apply_mapping_and_merge
from month_selector import process_history_columns
from summary import (
    merge_safety_inventory,
    append_unfulfilled_summary_columns,
    append_forecast_to_summary,
    merge_finished_inventory,
    append_product_in_progress
)

FIELD_MAPPINGS = {
    "unfulfilled_orders": {"è§„æ ¼": "è§„æ ¼", "å“å": "å“å", "æ™¶åœ†å“å": "æ™¶åœ†å“å"},
    "finished_products": {"è§„æ ¼": "äº§å“è§„æ ¼", "å“å": "äº§å“å“å", "æ™¶åœ†å“å": "æ™¶åœ†å‹å·"},
    "finished_inventory": {"è§„æ ¼": "è§„æ ¼", "å“å": "å“å", "æ™¶åœ†å“å": "WAFERå“å"},
    "safety": {"è§„æ ¼": "OrderInformation", "å“å": "ProductionNO.", "æ™¶åœ†å“å": "WaferID"},
    "forecast": {"è§„æ ¼": "äº§å“å‹å·", "å“å": "ProductionNO.", "æ™¶åœ†å“å": "æ™¶åœ†å“å"}
}


class PivotProcessor:
    def process(self, uploaded_files: dict, output_buffer, additional_sheets: dict = None):
        df_finished = pd.DataFrame()
        product_in_progress = pd.DataFrame()
        df_unfulfilled = pd.DataFrame()
    
        unmatched_safety = []
        unmatched_unfulfilled = []
        unmatched_forecast = []
        unmatched_finished = []
        unmatched_in_progress = []
    
        mapping_df = additional_sheets.get("mapping", pd.DataFrame())

        all_mapped_keys = set()
    
        with pd.ExcelWriter(output_buffer, engine="openpyxl") as writer:
    
            # âœ… Step 1: å¤„ç†æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œç”Ÿæˆ pivot
            for filename, file_obj in uploaded_files.items():
                try:
                    df = pd.read_excel(file_obj)
                    config = CONFIG["pivot_config"].get(filename)
                    if not config:
                        st.warning(f"âš ï¸ è·³è¿‡æœªé…ç½®çš„æ–‡ä»¶ï¼š{filename}")
                        continue
    
                    sheet_key = filename.replace(".xlsx", "")[:30]  # å¯æ›¿æ¢ä¸ºæ˜ å°„ key
                    if sheet_key in FIELD_MAPPINGS and not mapping_df.empty:
                        mapping_df.columns = [
                            "æ—§è§„æ ¼", "æ—§å“å", "æ—§æ™¶åœ†å“å",
                            "æ–°è§„æ ¼", "æ–°å“å", "æ–°æ™¶åœ†å“å",
                            "å°è£…å‚", "PC", "åŠæˆå“"
                        ] + list(mapping_df.columns[9:])
                        st.success(f"âœ… `{sheet_key}` æ­£åœ¨è¿›è¡Œæ–°æ—§æ–™å·æ›¿æ¢...")
                        df, mapped_keys = apply_mapping_and_merge(df, mapping_df, FIELD_MAPPINGS[sheet_key])
                        st.write("mapped_keys")
                        st.write(mapped_keys)
                        all_mapped_keys.update(mapped_keys)
    
                    if "date_format" in config:
                        df = self._process_date_column(df, config["columns"], config["date_format"])
    
                    pivoted = self._create_pivot(df, config)
                    sheet_name = REVERSE_MAPPING.get(sheet_key, sheet_key)
                    pivoted.to_excel(writer, sheet_name=sheet_name, index=False)
                    adjust_column_width(writer, sheet_name, pivoted)
                    # âœ… æ ‡é»„ï¼šå¦‚æœ _ç”±æ–°æ—§æ–™å·æ˜ å°„ å­˜åœ¨ï¼Œåˆ™æ ‡è®°
                    if "_ç”±æ–°æ—§æ–™å·æ˜ å°„" in pivoted.columns:
                        ws = writer.sheets[excel_sheet_name]
                        yellow_fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
                    
                        for i, is_mapped in enumerate(pivoted["_ç”±æ–°æ—§æ–™å·æ˜ å°„"], start=2):  # Excelä»ç¬¬2è¡Œå¼€å§‹
                            if is_mapped:
                                for col in range(1, ws.max_column + 1):
                                    ws.cell(row=i, column=col).fill = yellow_fill
                    
                        # åˆ é™¤æ ‡è®°åˆ—ï¼Œé¿å…æ±¡æŸ“è¾“å‡º
                        del pivoted["_ç”±æ–°æ—§æ–™å·æ˜ å°„"]

    
                    # ä¿å­˜å…³é”®æ•°æ®ç”¨äºåç»­åˆå¹¶
                    if sheet_key == "unfulfilled_orders":
                        df_unfulfilled = df
                        pivot_unfulfilled = pivoted
                    elif sheet_key == "finished_inventory":
                        df_finished = pivoted
                    elif sheet_key == "finished_products":
                        product_in_progress = pivoted
    
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶ `{filename}` å¤„ç†å¤±è´¥: {e}")
    
            # âœ… Step 2: æ„å»º summary åŸºç¡€
            if df_unfulfilled.empty:
                st.error("âŒ ç¼ºå°‘æœªäº¤è®¢å•æ•°æ®ï¼Œæ— æ³•æ„å»ºæ±‡æ€»")
                return
    
            summary_preview = df_unfulfilled[["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]].drop_duplicates().reset_index(drop=True)
    
            # âœ… Step 3: åˆå¹¶å„ç±»ä¿¡æ¯
            try:
                if "safety" in additional_sheets:
                    summary_preview, unmatched_safety = merge_safety_inventory(summary_preview, additional_sheets["safety"])
                    st.success("âœ… å·²åˆå¹¶å®‰å…¨åº“å­˜")
    
                summary_preview, unmatched_unfulfilled = append_unfulfilled_summary_columns(summary_preview, pivot_unfulfilled)
                st.success("âœ… å·²åˆå¹¶æœªäº¤è®¢å•")
    
                if "forecast" in additional_sheets:
                    forecast_df = additional_sheets["forecast"]
                    forecast_df.columns = forecast_df.iloc[0]
                    forecast_df = forecast_df[1:].reset_index(drop=True)
                    summary_preview, unmatched_forecast = append_forecast_to_summary(summary_preview, forecast_df)
                    st.success("âœ… å·²åˆå¹¶é¢„æµ‹æ•°æ®")
    
                if not df_finished.empty:
                    if not mapping_df.empty:
                        df_finished, mapped_keys = apply_mapping_and_merge(df_finished, mapping_df, FIELD_MAPPINGS["finished_inventory"])
                        all_mapped_keys.update(mapped_keys)
                    summary_preview, unmatched_finished = merge_finished_inventory(summary_preview, df_finished)
                    st.success("âœ… å·²åˆå¹¶æˆå“åº“å­˜")
                else:
                    st.warning("âš ï¸ å°šæœªè¯»å–æˆå“åº“å­˜ï¼ˆfinished_inventory.xlsxï¼‰ï¼Œè·³è¿‡åˆå¹¶")
    
                if not product_in_progress.empty:
                    if not mapping_df.empty:
                        product_in_progress, mapped_keys = apply_mapping_and_merge(product_in_progress, mapping_df, FIELD_MAPPINGS["finished_products"])
                        all_mapped_keys.update(mapped_keys)
                    summary_preview, unmatched_in_progress = append_product_in_progress(summary_preview, product_in_progress, mapping_df)
                    st.success("âœ… å·²åˆå¹¶æˆå“åœ¨åˆ¶")
                else:
                    st.warning("âš ï¸ å°šæœªè¯»å–æˆå“åœ¨åˆ¶ï¼ˆfinished_products.xlsxï¼‰ï¼Œè·³è¿‡åˆå¹¶")
    
            except Exception as e:
                st.error(f"âŒ æ±‡æ€»æ•°æ®åˆå¹¶å¤±è´¥: {e}")
                return
    
            # âœ… Step 4: å†™å…¥æ±‡æ€» Sheet
            summary_preview.to_excel(writer, sheet_name="æ±‡æ€»", index=False)
            adjust_column_width(writer, "æ±‡æ€»", summary_preview)
            ws = writer.sheets["æ±‡æ€»"]
    
            header_row = list(summary_preview.columns)
            unfulfilled_cols = [col for col in header_row if "æœªäº¤è®¢å•æ•°é‡" in col or col in ("æ€»æœªäº¤è®¢å•", "å†å²æœªäº¤è®¢å•æ•°é‡")]
            forecast_cols = [col for col in header_row if "é¢„æµ‹" in col]
            finished_cols = [col for col in header_row if col in ("æ•°é‡_HOLDä»“", "æ•°é‡_æˆå“ä»“", "æ•°é‡_åŠæˆå“ä»“")]
    
            merge_header_for_summary(
                ws, summary_preview,
                {
                    "å®‰å…¨åº“å­˜": (" InvWaf", " InvPart"),
                    "æœªäº¤è®¢å•": (unfulfilled_cols[0], unfulfilled_cols[-1]),
                    "é¢„æµ‹": (forecast_cols[0], forecast_cols[-1]) if forecast_cols else ("", ""),
                    "æˆå“åº“å­˜": (finished_cols[0], finished_cols[-1]) if finished_cols else ("", ""),
                    "æˆå“åœ¨åˆ¶": ("æˆå“åœ¨åˆ¶", "åŠæˆå“åœ¨åˆ¶")
                }
            )
    
            # âœ… Step 5: å†™å…¥é™„åŠ  sheetï¼ˆå®‰å…¨/é¢„æµ‹/æ˜ å°„ï¼‰
            for key, df in additional_sheets.items():
                if key == "mapping":
                    df.to_excel(writer, sheet_name="èµ›å“-æ–°æ—§æ–™å·", index=False)
                    adjust_column_width(writer, "èµ›å“-æ–°æ—§æ–™å·", df)
                else:
                    sheet_name = REVERSE_MAPPING.get(key, key)
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
                    adjust_column_width(writer, sheet_name, df)
    
            # âœ… Step 6: æ ‡çº¢æœªåŒ¹é…é¡¹
            try:
                if "safety" in additional_sheets:
                    mark_unmatched_keys_on_sheet(writer.sheets["èµ›å“-å®‰å…¨åº“å­˜"], unmatched_safety, wafer_col=1, spec_col=3, name_col=5)
                mark_unmatched_keys_on_sheet(writer.sheets["èµ›å“-æœªäº¤è®¢å•"], unmatched_unfulfilled, wafer_col=1, spec_col=2, name_col=3)
                mark_unmatched_keys_on_sheet(writer.sheets["èµ›å“-é¢„æµ‹"], unmatched_forecast, wafer_col=3, spec_col=1, name_col=2)
                writer.sheets["èµ›å“-é¢„æµ‹"].delete_rows(2)
                mark_unmatched_keys_on_sheet(writer.sheets["èµ›å“-æˆå“åº“å­˜"], unmatched_finished, wafer_col=1, spec_col=2, name_col=3)
                mark_unmatched_keys_on_sheet(writer.sheets["èµ›å“-æˆå“åœ¨åˆ¶"], unmatched_in_progress, wafer_col=3, spec_col=4, name_col=5)
                writer.sheets["èµ›å“-æ–°æ—§æ–™å·"].delete_rows(2)
                st.success("âœ… å·²å®ŒæˆæœªåŒ¹é…é¡¹æ ‡è®°")
            except Exception as e:
                st.warning(f"âš ï¸ æœªåŒ¹é…æ ‡è®°å¤±è´¥ï¼š{e}")

            st.write("all_mapped_keys")
            st.write(all_mapped_keys)
            mark_keys_on_sheet(writer.sheets["æ±‡æ€»"], all_mapped_keys, key_cols=(1, 2, 3))
    
            # âœ… Step 7: æ·»åŠ ç­›é€‰å™¨
            for name, ws in writer.sheets.items():
                col_letter = get_column_letter(ws.max_column)
                if name == "æ±‡æ€»":
                    ws.auto_filter.ref = f"A2:{col_letter}2"
                else:
                    ws.auto_filter.ref = f"A1:{col_letter}1"
    
            output_buffer.seek(0)


    def _process_date_column(self, df, date_col, date_format):
        if pd.api.types.is_numeric_dtype(df[date_col]):
            df[date_col] = df[date_col].apply(self._excel_serial_to_date)
        else:
            df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

        new_col = f"{date_col}_å¹´æœˆ"
        df[new_col] = df[date_col].dt.strftime(date_format)
        df[new_col] = df[new_col].fillna("æœªçŸ¥æ—¥æœŸ")
        return df

    def _excel_serial_to_date(self, serial):
        try:
            return datetime(1899, 12, 30) + timedelta(days=float(serial))
        except:
            return pd.NaT

    def _create_pivot(self, df, config):
        config = config.copy()
        if "date_format" in config:
            config["columns"] = f"{config['columns']}_å¹´æœˆ"


        pivoted = pd.pivot_table(
            df,
            index=config["index"],
            columns=config["columns"],
            values=config["values"],
            aggfunc=config["aggfunc"],
            fill_value=0
        )


        # åˆå¹¶å¤šçº§åˆ—åï¼ˆå¦‚ (è®¢å•æ•°é‡, 2024-05) â†’ è®¢å•æ•°é‡_2024-05ï¼‰
        pivoted.columns = [f"{col[0]}_{col[1]}" if isinstance(col, tuple) else str(col) for col in pivoted.columns]


        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤åˆ—å
        if pd.Series(pivoted.columns).duplicated().any():
            from pandas.io.parsers import ParserBase
            original_cols = pivoted.columns
            deduped_cols = ParserBase({'names': original_cols})._maybe_dedup_names(original_cols)
            pivoted.columns = deduped_cols


        # é‡ç½® index ä»¥é¿å… to_excel å‡ºé”™
        pivoted = pivoted.reset_index()

        # âœ… ä»…å¯¹æœªäº¤è®¢å•è¡¨è§¦å‘å†å²æ•°æ®åˆå¹¶
        if CONFIG.get("selected_month") and config.get("values") and "æœªäº¤è®¢å•æ•°é‡" in config.get("values"):
            st.info(f"ğŸ“… åˆå¹¶å†å²æ•°æ®è‡³ï¼š{CONFIG['selected_month']}")
            pivoted = process_history_columns(pivoted, config, CONFIG["selected_month"])
        return pivoted
