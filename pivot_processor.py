import os
import re
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font
from openpyxl import load_workbook
from config import CONFIG, REVERSE_MAPPING
from excel_utils import (
    adjust_column_width, 
    merge_header_for_summary, 
    mark_unmatched_keys_on_sheet
)
from mapping_utils import apply_mapping_and_merge
from month_selector import process_history_columns
from summary import (
    merge_safety_inventory,
    append_unfulfilled_summary_columns,
    append_forecast_to_summary,
    merge_finished_inventory,
    append_product_in_progress
)

FIELD_MAPPINGS = {
    "unfulfilled_orders": {"è§„æ ¼": "è§„æ ¼", "å“å": "å“å", "æ™¶åœ†å“å": "æ™¶åœ†å“å"},
    "finished_products": {"è§„æ ¼": "äº§å“è§„æ ¼", "å“å": "äº§å“å“å", "æ™¶åœ†å“å": "æ™¶åœ†å‹å·"},
    "finished_inventory": {"è§„æ ¼": "è§„æ ¼", "å“å": "å“å", "æ™¶åœ†å“å": "WAFERå“å"},
    "safety": {"è§„æ ¼": "OrderInformation", "å“å": "ProductionNO.", "æ™¶åœ†å“å": "WaferID"},
    "forecast": {"è§„æ ¼": "äº§å“å‹å·", "å“å": "ProductionNO.", "æ™¶åœ†å“å": "æ™¶åœ†å“å"}
}


class PivotProcessor:
    def process(self, uploaded_files: dict, output_buffer, additional_sheets: dict = None):
        with pd.ExcelWriter(output_buffer, engine="openpyxl") as writer:
            for filename, file_obj in uploaded_files.items():
                try:
                    df = pd.read_excel(file_obj)
                    st.write(filename)
                    config = CONFIG["pivot_config"].get(filename)
                    if not config:
                        st.warning(f"âš ï¸ è·³è¿‡æœªé…ç½®çš„æ–‡ä»¶ï¼š{filename}")
                        continue


                    sheet_name = filename[:30].replace(".xlsx", "")
                    st.write(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: `{filename}` â†’ Sheet: `{sheet_name}`")


                    st.write(f"åŸå§‹æ•°æ®ç»´åº¦: {df.shape}")
                    st.dataframe(df.head(3))


                    # æ—¥æœŸå¤„ç†
                    if "date_format" in config:
                        date_col = config["columns"]
                        df = self._process_date_column(df, date_col, config["date_format"])


                    # æ˜ å°„æ›¿æ¢ï¼ˆå¦‚æœæœ‰ï¼‰
                    st.write("additional_sheets")
                    st.write(additional_sheets)
                    if sheet_name in FIELD_MAPPINGS and "mapping" in (additional_sheets or {}):
                        mapping_df = additional_sheets["mapping"]


                        try:
                            mapping_df.columns = [
                                "æ—§è§„æ ¼", "æ—§å“å", "æ—§æ™¶åœ†å“å",
                                "æ–°è§„æ ¼", "æ–°å“å", "æ–°æ™¶åœ†å“å",
                                "å°è£…å‚", "PC", "åŠæˆå“"
                            ] + list(mapping_df.columns[9:])
                            st.success(f"âœ… `{sheet_name}` æ­£åœ¨è¿›è¡Œæ–°æ—§æ–™å·æ›¿æ¢...")
                        except Exception as e:
                            st.error(f"âŒ `{sheet_name}` æ›¿æ¢å‰åˆ—åå¤±è´¥ï¼š{e}")
                            st.write("åˆ—åï¼š", mapping_df.columns.tolist())
                            continue

                        
                        df = apply_mapping_and_merge(df, mapping_df, FIELD_MAPPINGS[sheet_name])


                    # æ„å»ºé€è§†è¡¨
                    pivoted = self._create_pivot(df, config)
                    pivoted_display = pivoted.reset_index(drop=True)
                    if sheet_name == "finished_inventory":
                        df_finished = pivoted
                    elif sheet_name == "finished_products":
                        product_in_progress = pivoted

                    st.write(f"âœ… Pivot è¡¨åˆ›å»ºæˆåŠŸï¼Œç»´åº¦ï¼š{pivoted_display.shape}")
                    st.dataframe(pivoted_display.head(3))


                    excel_sheet_name = REVERSE_MAPPING.get(sheet_name, sheet_name)
                    pivoted.to_excel(writer, sheet_name=excel_sheet_name, index=False)
                    adjust_column_width(writer, excel_sheet_name, pivoted)

                    # åˆå§‹åŒ–æœªåŒ¹é…å˜é‡ï¼Œé˜²æ­¢å¼•ç”¨å‰æœªèµ‹å€¼
                    unmatched_safety = []
                    unmatched_unfulfilled = []
                    unmatched_forecast = []
                    unmatched_finished = []
                    unmatched_in_progress = []


                    # âœ… å¦‚æœå½“å‰æ˜¯â€œæœªäº¤è®¢å•â€sheetï¼Œåˆ™æ‹·è´å‰ä¸‰åˆ—åˆ°æ–° sheet
                    if sheet_name == "èµ›å“-æœªäº¤è®¢å•":
                        try:
                            # æå–å‰ä¸‰åˆ—ä½œä¸ºæ±‡æ€»åŸºç¡€
                            summary_preview = df[["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]].drop_duplicates().reset_index(drop=True)

                            # è¿½åŠ å®‰å…¨åº“å­˜ä¿¡æ¯
                            df_safety = additional_sheets["safety"]
                            summary_preview, unmatched_safety = merge_safety_inventory(summary_preview, df_safety)
                            st.success("âœ… å·²åˆå¹¶å®‰å…¨åº“å­˜æ•°æ®")
                            st.write(f"å®‰å…¨åº“å­˜æ ‡çº¢ï¼š{unmatched_safety}")


                            # è¿½åŠ æœªäº¤è®¢å•ä¿¡æ¯
                            summary_preview, unmatched_unfulfilled = append_unfulfilled_summary_columns(summary_preview, pivoted)
                            st.success("âœ… å·²åˆå¹¶æœªäº¤è®¢å•æ•°æ®")
                            st.write(f"æœªäº¤è®¢å•æ ‡çº¢ï¼š{unmatched_unfulfilled}")

                            # è¿½åŠ é¢„æµ‹ä¿¡æ¯
                            df_forecast = additional_sheets["èµ›å“-é¢„æµ‹"]
                            df_forecast.columns = df_forecast.iloc[0]   # ç¬¬äºŒè¡Œè®¾ä¸º header
                            df_forecast = df_forecast[1:].reset_index(drop=True)  # åˆ é™¤ç¬¬ä¸€è¡Œå¹¶é‡å»ºç´¢å¼•
                            summary_preview, unmatched_forecast = append_forecast_to_summary(summary_preview, df_forecast)
                            st.success("âœ… å·²åˆå¹¶é¢„æµ‹æ•°æ®")
                            st.write(f"é¢„æµ‹æ ‡çº¢ï¼š{unmatched_forecast}")

                            # è¿½åŠ æˆå“åº“å­˜ä¿¡æ¯
                            df_finished = apply_mapping_and_merge(df_finished, mapping_df, FIELD_MAPPINGS[sheet_name])
                            st.write(df_finished)
                            summary_preview, unmatched_finished = merge_finished_inventory(summary_preview, df_finished)
                            st.success("âœ… å·²åˆå¹¶æˆå“åº“å­˜")
                            st.write(f"åº“å­˜ä¿¡æ¯æ ‡çº¢ï¼š{unmatched_finished}")

                            # è¿½åŠ æˆå“åœ¨åˆ¶ä¿¡æ¯
                            product_in_progress = apply_mapping_and_merge(product_in_progress, mapping_df, FIELD_MAPPINGS[sheet_name])
                            st.write(product_in_progress)
                            summary_preview, unmatched_in_progress = append_product_in_progress(summary_preview, product_in_progress, mapping_df)
                            st.success("âœ… å·²åˆå¹¶æˆå“åœ¨åˆ¶")
                            st.write(f"åœ¨åˆ¶ä¿¡æ¯æ ‡çº¢ï¼š{unmatched_in_progress}")



                            # å†™å…¥â€œæ±‡æ€»â€ sheet
                            summary_preview.to_excel(writer, sheet_name="æ±‡æ€»", index=False)
                            adjust_column_width(writer, "æ±‡æ€»", summary_preview)
                            st.success("âœ… å·²å†™å…¥æ±‡æ€»Sheet")



                            # æ‰“å¼€ worksheet è¿›è¡Œæ ¼å¼åŒ–
                            ws = writer.sheets["æ±‡æ€»"]
                            header_row = list(summary_preview.columns)


                            # âœ… æ‰¾å‡ºæ‰€æœ‰â€œæœªäº¤è®¢å•â€ç›¸å…³åˆ—ï¼ˆé¡ºåºä¿ç•™ï¼‰
                            unfulfilled_cols = [col for col in header_row if (
                                col == "æ€»æœªäº¤è®¢å•" or 
                                col == "å†å²æœªäº¤è®¢å•æ•°é‡" or 
                                "æœªäº¤è®¢å•æ•°é‡" in col
                              )]
                            st.write(unfulfilled_cols)

                            # âœ… æ‰¾å‡ºæ‰€æœ‰â€œé¢„æµ‹â€ç›¸å…³åˆ—ï¼ˆé¡ºåºä¿ç•™ï¼‰
                            forecast_cols = [col for col in header_row if (
                                "é¢„æµ‹" in col
                            )]
                            st.write(forecast_cols)

                            # âœ… æ‰¾å‡ºæ‰€æœ‰â€œæˆå“åº“å­˜â€ç›¸å…³åˆ—ï¼ˆé¡ºåºä¿ç•™ï¼‰
                            finished_cols = [col for col in header_row if (
                                col == "æ•°é‡_HOLDä»“" or 
                                col == "æ•°é‡_æˆå“ä»“" or 
                                col == "æ•°é‡_åŠæˆå“ä»“"
                            )]
                            st.write(finished_cols)


                            merge_header_for_summary(
                                ws,
                                summary_preview,
                                {
                                    "å®‰å…¨åº“å­˜": (" InvWaf", " InvPart"),
                                    "æœªäº¤è®¢å•": (unfulfilled_cols[0], unfulfilled_cols[-1]),
                                    "é¢„æµ‹": (forecast_cols[0], forecast_cols[-1]),
                                    "æˆå“åº“å­˜": (finished_cols[0], finished_cols[-1]),
                                    "æˆå“åœ¨åˆ¶": ("æˆå“åœ¨åˆ¶", "åŠæˆå“åœ¨åˆ¶")
                                 }
                            )



                        except Exception as e:
                            st.error(f"âŒ å†™å…¥æ±‡æ€»å¤±è´¥: {e}")

                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶ `{filename}` å¤„ç†å¤±è´¥: {e}")

            # å†™å…¥æ–°æ—§æ–™å·
            df_mapping = additional_sheets.get("mapping")
            if df_mapping is not None:
                df_mapping.to_excel(writer, sheet_name="èµ›å“-æ–°æ—§æ–™å·", index=False)
                adjust_column_width(writer, "èµ›å“-æ–°æ—§æ–™å·", df_mapping)



            # å†™å…¥é™„åŠ  sheetï¼ˆå¦‚é¢„æµ‹ã€å®‰å…¨åº“å­˜ï¼‰
            if additional_sheets:
                for sheet_key, df in additional_sheets.items():
                    if sheet_key == "mapping":
                        continue
                    try:
                        sheet_name = REVERSE_MAPPING.get(sheet_key, sheet_key)  # è‹±æ–‡ âœ ä¸­æ–‡
                        st.write(f"ğŸ“ æ­£åœ¨å†™å…¥é™„åŠ è¡¨ï¼š{sheet_name}ï¼Œæ•°æ®ç»´åº¦ï¼š{df.shape}")
                        df.to_excel(writer, sheet_name=sheet_name, index=False)
                        adjust_column_width(writer, sheet_name, df)
                    except Exception as e:
                        st.error(f"âŒ å†™å…¥é™„åŠ  Sheet `{sheet_key}` å¤±è´¥: {e}")

            # æ ‡è®°æœªåŒ¹é…é¡¹
            try:
                ws = writer.sheets["èµ›å“-å®‰å…¨åº“å­˜"]
                mark_unmatched_keys_on_sheet(ws, unmatched_safety, wafer_col=1, spec_col=3, name_col=5)
               
                ws = writer.sheets["èµ›å“-æœªäº¤è®¢å•"]
                mark_unmatched_keys_on_sheet(ws, unmatched_unfulfilled, wafer_col=1, spec_col=2, name_col=3)
                
                ws = writer.sheets["èµ›å“-é¢„æµ‹"]
                mark_unmatched_keys_on_sheet(ws, unmatched_forecast, wafer_col=3, spec_col=1, name_col=2)
                ws.delete_rows(2)  # åˆ é™¤ç¬¬ 1 è¡Œ
                
                ws = writer.sheets["èµ›å“-æˆå“åº“å­˜"]
                mark_unmatched_keys_on_sheet(ws, unmatched_finished, wafer_col=1, spec_col=2, name_col=3)
               
                ws = writer.sheets["èµ›å“-æˆå“åœ¨åˆ¶"]
                mark_unmatched_keys_on_sheet(ws, unmatched_in_progress, wafer_col=3, spec_col=4, name_col=5)

                ws = writer.sheets["èµ›å“-æ–°æ—§æ–™å·"]
                ws.delete_rows(2)  # åˆ é™¤ç¬¬ 1 è¡Œ
                
                
                st.success("âœ… å·²å®ŒæˆæœªåŒ¹é…é¡¹æ ‡è®°")

                # âœ… æ‰€æœ‰å†™å…¥å®Œæˆåå†åŠ ç­›é€‰å™¨ï¼Œé¿å…è¢« to_excel è¦†ç›–
                for sheet_name, ws in writer.sheets.items():
                    st.write(sheet_name)
                    # å¦‚æœç¬¬1è¡Œæ˜¯ä½ éœ€è¦çš„ headerï¼Œå°±æ·»åŠ ç­›é€‰å™¨
                    col_letter = get_column_letter(ws.max_column)
                    if sheet_name == "æ±‡æ€»":
                        ws.auto_filter.ref = f"A2:{col_letter}2"
                    else:
                        ws.auto_filter.ref = f"A1:{col_letter}1"

            except Exception as e:
                st.error(f"âŒ æ ‡è®°æœªåŒ¹é…é¡¹å¤±è´¥: {e}")
        output_buffer.seek(0)

    def _process_date_column(self, df, date_col, date_format):
        if pd.api.types.is_numeric_dtype(df[date_col]):
            df[date_col] = df[date_col].apply(self._excel_serial_to_date)
        else:
            df[date_col] = pd.to_datetime(df[date_col], errors="coerce")

        new_col = f"{date_col}_å¹´æœˆ"
        df[new_col] = df[date_col].dt.strftime(date_format)
        df[new_col] = df[new_col].fillna("æœªçŸ¥æ—¥æœŸ")
        return df

    def _excel_serial_to_date(self, serial):
        try:
            return datetime(1899, 12, 30) + timedelta(days=float(serial))
        except:
            return pd.NaT

    def _create_pivot(self, df, config):
        config = config.copy()
        if "date_format" in config:
            config["columns"] = f"{config['columns']}_å¹´æœˆ"


        pivoted = pd.pivot_table(
            df,
            index=config["index"],
            columns=config["columns"],
            values=config["values"],
            aggfunc=config["aggfunc"],
            fill_value=0
        )


        # åˆå¹¶å¤šçº§åˆ—åï¼ˆå¦‚ (è®¢å•æ•°é‡, 2024-05) â†’ è®¢å•æ•°é‡_2024-05ï¼‰
        pivoted.columns = [f"{col[0]}_{col[1]}" if isinstance(col, tuple) else str(col) for col in pivoted.columns]


        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤åˆ—å
        if pd.Series(pivoted.columns).duplicated().any():
            from pandas.io.parsers import ParserBase
            original_cols = pivoted.columns
            deduped_cols = ParserBase({'names': original_cols})._maybe_dedup_names(original_cols)
            pivoted.columns = deduped_cols


        # é‡ç½® index ä»¥é¿å… to_excel å‡ºé”™
        pivoted = pivoted.reset_index()

        # âœ… ä»…å¯¹æœªäº¤è®¢å•è¡¨è§¦å‘å†å²æ•°æ®åˆå¹¶
        if CONFIG.get("selected_month") and config.get("values") and "æœªäº¤è®¢å•æ•°é‡" in config.get("values"):
            st.info(f"ğŸ“… åˆå¹¶å†å²æ•°æ®è‡³ï¼š{CONFIG['selected_month']}")
            pivoted = process_history_columns(pivoted, config, CONFIG["selected_month"])
        return pivoted
